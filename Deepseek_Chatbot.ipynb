{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7154066b-e4b0-42c2-91f9-8505b7f77537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import ollama\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cddbc89-94b9-47c2-a473-50d8f14683c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"deepseek-r1:7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9cc5e21-6f4d-4c77-9cf5-cade1eb385a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hi there, how can I help you? What is pyspark?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': input(\"Hi there, how can I help you?\")\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfd8868b-d716-46df-b9b9-5ec0f9e90277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "\n",
       "</think>\n",
       "\n",
       "Pyspark is a Python API for Apache Spark, enabling users to leverage Spark's distributed processing capabilities directly within Python. It simplifies working with large-scale data by providing high-level functions and classes for operations like mapreduce, MLlib algorithms, and more.\n",
       "\n",
       "Key features of PySpark include:\n",
       "\n",
       "1. **High-Level APIs**: Simplified API access to Spark functions.\n",
       "2. **Integration**: Easily integrates with existing Python-based workflows and tools.\n",
       "3. **MLlib**: Access to machine learning algorithms directly from PySpark.\n",
       "4. **Distributed Processing**: Handles large datasets by distributing computations across a cluster.\n",
       "\n",
       "To use PySpark:\n",
       "\n",
       "1. **Setup**: Install the required libraries:\n",
       "   ```bash\n",
       "   pip install findspark pyspark\n",
       "   ```\n",
       "2. **Initialization**:\n",
       "   ```python\n",
       "   import findspark\n",
       "   from pyspark import SparkContext\n",
       "\n",
       "   findspark.init()\n",
       "   sc = SparkContext.getOrCreate()\n",
       "   ```\n",
       "3. **Usage**: Utilize PySpark functions for data processing, transformations, and actions.\n",
       "\n",
       "Pyspark is ideal for developers who prefer working within Python but need the power of Spark's distributed computing framework."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = ollama.chat(\n",
    "        model=MODEL, \n",
    "        messages=messages, \n",
    "        options={'think': False}\n",
    "    )\n",
    "display(Markdown(response['message']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35750525-aff6-4df1-bfac-741d4e06fdbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
